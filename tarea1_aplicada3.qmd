---
title: "Tarea 1"
lang: es
author: "Marcelino"
date: today
format:
  html:
    page-layout: full
    embed-resources: true
---


```{r}
library(tidymodels)
library(discrim)

library(corrr)
library(paletteer)
library(keras)
data1 <- dataset_mnist()
data2 <- iris


```

```{r, error=TRUE}

# Extraer imágenes y etiquetas de entrenamiento
train_images <- data1$train$x
train_labels <- data1$train$y

# Filtrar sólo los dígitos 1 y 3
train_indices <- which(train_labels == 1 | train_labels == 3)
train_images_filtered <- train_images[train_indices,,]
train_labels_filtered <- train_labels[train_indices]

# 1. Aplanar las imágenes
train_images_flattened <- array_reshape(train_images_filtered, c(nrow(train_images_filtered), 28*28))

# 2. Convertir a data.frame
df_images <- as.data.frame(train_images_flattened)
df_labels <- data.frame(label = train_labels_filtered)

# 3. Combinar ambos data.frames
df_combined <- cbind(df_labels, df_images)

# Convertir la columna 'label' a un factor
df_combined$label <- as.factor(df_combined$label)

# modelo LDA

lda_spec <- discrim_linear() |>
  set_mode("classification") |>
  set_engine("MASS")

lda_fit <- lda_spec |>
  fit(label ~ ., data = df_combined) #modificar

augment(lda_fit, new_data = df_combined) |>
  conf_mat(truth = Species, estimate = .pred_class) |>
  autoplot(type = "heatmap")

augment(lda_fit, new_data = df_combined) |>
  accuracy(truth = Species, estimate = .pred_class)

augment(lda_fit, new_data = df_combined) |>
  recall(truth = Species, estimate = .pred_class)

augment(lda_fit, new_data = df_combined) |>
  precision(truth = Species, estimate = .pred_class)

qda_fit |>
  pluck("fit")
```

```{r, error=TRUE}
qda_spec <- discrim_quad() |>
  set_mode("classification") |>
  set_engine("MASS")

qda_fit <- qda_spec |>
  fit(Species ~ ., data = data2) #modificar

augment(qda_fit, new_data = data2) |>
  conf_mat(truth = Species, estimate = .pred_class) |>
  autoplot(type = "heatmap")

augment(qda_fit, new_data = data2) |>
  accuracy(truth = Species, estimate = .pred_class)

augment(qda_fit, new_data = data2) |>
  recall(truth = Species, estimate = .pred_class)

augment(qda_fit, new_data = data2) |>
  precision(truth = Species, estimate = .pred_class)

qda_fit |>
  pluck("fit")
```

```{r, error=TRUE}

# Sample data
set.seed(123)
data <- matrix(rnorm(30), ncol=2)
colnames(data) <- c("X", "Y")

# Visualize the data
plot(data, pch=19, col="blue", xlab="X", ylab="Y", main="Sample Data Points")

# Compute the distance matrix
dist_matrix <- dist(data)

# Agglomerative clustering from scratch
agglomerative_clustering <- function(dist_matrix, linkage = "single") {
  n <- nrow(dist_matrix)
  clusters <- list()
  for (i in 1:n) {
    clusters[[i]] <- c(i)
  }

  while (length(clusters) > 1) {
    min_dist <- Inf
    combine <- c(0, 0)

    for (i in 1:(length(clusters) - 1)) {
      for (j in (i + 1):length(clusters)) {
        cluster_i <- clusters[[i]]
        cluster_j <- clusters[[j]]

        if (linkage == "single") {
          current_dist <- min(dist_matrix[cluster_i, cluster_j])
        } else if (linkage == "complete") {
          current_dist <- max(dist_matrix[cluster_i, cluster_j])
        } else if (linkage == "average") {
          current_dist <- mean(dist_matrix[cluster_i, cluster_j])
        }

        if (current_dist < min_dist) {
          min_dist <- current_dist
          combine <- c(i, j)
        }
      }
    }

    new_cluster <- c(clusters[[combine[1]]], clusters[[combine[2]]])
    clusters <- clusters[-combine]
    clusters[[length(clusters) + 1]] <- new_cluster
  }
  
  return(clusters)
}







```


```{r, error=TRUE}
dist_matrix <- as.matrix(dist(data))

# Initialize clusters
clusters <- list()
for (i in 1:nrow(dist_matrix)) {
    clusters[[i]] <- c(i)
}

# Single-linkage function
single_linkage_distance <- function(cluster1, cluster2, dist_matrix) {
    min_distance <- Inf
    for (i in cluster1) {
        for (j in cluster2) {
            if (dist_matrix[i,j] < min_distance) {
                min_distance <- dist_matrix[i,j]
            }
        }
    }
    return(min_distance)
}

# Modify the initialization of hc_history
hc_history <- data.frame(merge1 = integer(nrow(dist_matrix) - 1),
                         merge2 = integer(nrow(dist_matrix) - 1),
                         height = double(nrow(dist_matrix) - 1))

# Modify the part where we record the merge history
for (step in 1:(nrow(dist_matrix) - 1)) {
    # ... [rest of the loop code remains the same]
    
    # Record the merge history
    hc_history[step, "merge1"] <- closest_clusters[1]
    hc_history[step, "merge2"] <- closest_clusters[2]
    hc_history[step, "height"] <- min_distance
}


# Plot the dendrogram
# Convert hc_history to an hclust object
hc <- list()

# The merge matrix for hclust is slightly different. It represents which clusters/items are merged at each step. 
# Negative values indicate original data points (leaf nodes), while positive values indicate internal nodes.
# Convert our merge history to this format:
n <- nrow(dist_matrix)
hc$merge <- matrix(0, n-1, 2)
m <- max(hc_history$merge1, hc_history$merge2)
hc$merge[, 1] <- ifelse(hc_history$merge1 > n, hc_history$merge1 - n + m, -hc_history$merge1)
hc$merge[, 2] <- ifelse(hc_history$merge2 > n, hc_history$merge2 - n + m, -hc_history$merge2)

hc$height <- hc_history$height
hc$order <- order.dendrogram(as.dendrogram(hc))
hc$labels <- 1:n
hc$method <- "single"
class(hc) <- "hclust"

# Now plot
plot(hc, main="Single-linkage Hierarchical Clustering", sub="", xlab="", ylab="Height")


```

```{r, error=TRUE}
# 1. Correct the merge history in hc_history

# Initialize clusters
clusters <- lapply(1:nrow(dist_matrix), function(x) c(x))
hc_history <- data.frame(merge1 = integer(nrow(dist_matrix) - 1),
                         merge2 = integer(nrow(dist_matrix) - 1),
                         height = double(nrow(dist_matrix) - 1))

for (step in 1:(nrow(dist_matrix) - 1)) {
    # Find the two closest clusters
    min_distance <- Inf
    for (i in 1:(length(clusters)-1)) {
        for (j in (i+1):length(clusters)) {
            current_distance <- single_linkage_distance(clusters[[i]], clusters[[j]], dist_matrix)
            if (current_distance < min_distance) {
                min_distance <- current_distance
                closest_clusters <- c(i,j)
            }
        }
    }
    
    # Merge clusters
    new_cluster <- c(clusters[[closest_clusters[1]]], clusters[[closest_clusters[2]]])
    clusters[[closest_clusters[1]]] <- new_cluster
    clusters <- clusters[-closest_clusters[2]]
    
    # Record the merge history
    hc_history[step, "merge1"] <- closest_clusters[1]
    hc_history[step, "merge2"] <- closest_clusters[2]
    hc_history[step, "height"] <- min_distance
}

# 2. Construct the dendrogram from hc_history

# The merge matrix for hclust represents which clusters/items are merged at each step. 
merge_matrix <- matrix(0, n-1, 2)
for (i in 1:(n-1)) {
    # if merge value is larger than n, then it represents a merged cluster, 
    # otherwise it represents an original item
    merge_matrix[i, 1] <- ifelse(hc_history$merge1[i] > n, -(hc_history$merge1[i] - n), hc_history$merge1[i])
    merge_matrix[i, 2] <- ifelse(hc_history$merge2[i] > n, -(hc_history$merge2[i] - n), hc_history$merge2[i])
}

hc <- list()
hc$merge <- merge_matrix
hc$height <- hc_history$height
hc$order <- NULL
hc$labels <- 1:n
hc$method <- "single"
class(hc) <- "hclust"




```

```{r, error=TRUE}

dist_matrix <- dist(data)
# Single-linkage
single_linkage <- hclust(dist_matrix, method="single")
plot(single_linkage, main="Single-linkage Hierarchical Clustering", sub="", xlab="", ylab="Height")

# Average-linkage
average_linkage <- hclust(dist_matrix, method="average")
plot(average_linkage, main="Average-linkage Hierarchical Clustering", sub="", xlab="", ylab="Height")

# Complete-linkage
complete_linkage <- hclust(dist_matrix, method="complete")
plot(complete_linkage, main="Complete-linkage Hierarchical Clustering", sub="", xlab="", ylab="Height")

```


# Ejercicio 12.13
```{r}
# Create the dataframe
cereal_data <- data.frame(
  Cereal = c("Life", "Grape Nuts", "Super Sugar Crisp", "Special K", "Rice Krispies", "Raisin Bran", 
             "Product 19", "Wheaties", "Total", "Puffed Rice", "Sugar Corn Pops", "Sugar Smacks"),
  Protein_gm = c(6, 3, 2, 6, 2, 3, 2, 3, 3, 1, 1, 2),
  Carbohydrates_gm = c(19, 23, 26, 21, 25, 28, 24, 23, 23, 13, 26, 25),
  Fat_gm = c(1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0),
  Calories_per_oz = c(110, 100, 110, 110, 110, 120, 110, 110, 110, 50, 110, 110),
  Vitamin_A_pct_daily_allowance = c(0, 25, 25, 25, 25, 25, 100, 25, 100, 0, 25, 25)
)

# Print the dataframe
cereal_data

# Compute the distance matrix
dist_matrix <- dist(cereal_data[1:12,2:6])

# Single-linkage
single_linkage <- hclust(dist_matrix, method="single")
plot(single_linkage, main="Single-linkage Hierarchical Clustering", sub="", xlab="", ylab="Height")

#Complete-linkage

complete_linkage <- hclust(dist_matrix, method="complete")
plot(complete_linkage, main="Complete-linkage Hierarchical Clustering", sub="", xlab="", ylab="Height")
```


# Ejercicio 12.14
```{r}
# Create the dataframe
cereal_data <- data.frame(
  Cereal = c("Life", "Grape Nuts", "Super Sugar Crisp", "Special K", "Rice Krispies", "Raisin Bran", 
             "Product 19", "Wheaties", "Total", "Puffed Rice", "Sugar Corn Pops", "Sugar Smacks"),
  Protein_gm = c(6, 3, 2, 6, 2, 3, 2, 3, 3, 1, 1, 2),
  Carbohydrates_gm = c(19, 23, 26, 21, 25, 28, 24, 23, 23, 13, 26, 25),
  Fat_gm = c(1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0),
  Calories_per_oz = c(110, 100, 110, 110, 110, 120, 110, 110, 110, 50, 110, 110),
  Vitamin_A_pct_daily_allowance = c(0, 25, 25, 25, 25, 25, 100, 25, 100, 0, 25, 25)
)

# Print the dataframe
cereal_data

# Exclude the Cereal column
clustering_data <- cereal_data[,-1]

# Choose the optimal number of clusters (for demonstration, let's say 3)
set.seed(123)  # Set seed for reproducibility
clusters <- kmeans(clustering_data, centers=2, nstart=25)

# Add cluster results to the original data
cereal_data$cluster <- as.factor(clusters$cluster)

# Print the dataframe with clusters
print(cereal_data)

```


```{r}
clusters <- kmeans(clustering_data, centers=3, nstart=25)

# Add cluster results to the original data
cereal_data$cluster <- as.factor(clusters$cluster)

# Print the dataframe with clusters
print(cereal_data)
```

```{r}
clusters <- kmeans(clustering_data, centers=4, nstart=25)

# Add cluster results to the original data
cereal_data$cluster <- as.factor(clusters$cluster)

# Print the dataframe with clusters
print(cereal_data)
```

**Poner interpretación**

